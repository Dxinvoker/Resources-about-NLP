**Resources-about-NLP** 

Machine Learning

[RF、GBDT、XGBoost面试级整理](https://blog.csdn.net/qq_28031525/article/details/70207918)

[机器学习面试之各种优化器的比较](https://www.jianshu.com/p/ee39eca29117)

[对Focal Loss的认识](http://skyhigh233.com/blog/2018/04/04/focalloss/)

[简单的交叉熵损失函数，你真的懂了吗？](https://zhuanlan.zhihu.com/p/38241764)

[漫谈：机器学习中距离和相似性度量方法](https://www.cnblogs.com/daniel-D/p/3244718.html)

[EM-最大期望算法](http://www.csuldw.com/2015/12/02/2015-12-02-EM-algorithms/)

[通俗理解kaggle比赛大杀器xgboost](https://www.julyedu.com/question/big/kp_id/23/ques_id/2590)

[为什么L1稀疏L2平滑？](https://blog.csdn.net/li8zi8fa/article/details/77649973)

[这可能是你看过的最用心的【决策树算法】介绍文章](https://zhuanlan.zhihu.com/p/32053821)

Deep Learning

Deep Learning基础

[RNN](https://blog.csdn.net/zhaojc1995/article/details/80572098)

PyTorch

[LSTM细节分析理解（pytorch版）](<https://zhuanlan.zhihu.com/p/79064602>)

文本分类

[在文本分类任务中，有哪些论文中很少提及却对性能有重要影响的tricks？](https://www.zhihu.com/question/265357659)

语义相似度

[深度学习解决 NLP 问题：语义相似度计算](https://cloud.tencent.com/developer/article/1005600)

[浅析文本相似度](https://blog.csdn.net/qq_28031525/article/details/79596376)

Seq2Seq & Transfomer & Attention

[真正的完全图解Seq2Seq Attention模型](https://zhuanlan.zhihu.com/p/40920384)

[Transformer 模型的 PyTorch 实现](https://juejin.im/post/5b9f1af0e51d450e425eb32d)

[哈佛大学的Transformer实现](https://nlp.seas.harvard.edu/2018/04/03/attention.html)

[Details Need More Attention: Transformer 没有被提到的细节](https://zhuanlan.zhihu.com/p/79987949)

[NLPer看过来，一些关于Transformer的问题整理](https://www.nowcoder.com/discuss/258321?type=post&order=hot&pos=&page=1)

[Attention? Attention!](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html)

[transformer中的attention为什么scaled?](https://www.zhihu.com/question/339723385)

[为什么Transformer 需要进行 Multi-head Attention？](https://www.zhihu.com/question/341222779)

词向量

[nlp中的词向量对比：word2vec/glove/fastText/elmo/GPT/bert](https://zhuanlan.zhihu.com/p/56382372)

[doc2vec原理及实践](https://blog.csdn.net/John_xyz/article/details/79208564)

[GloVe与word2vec的区别](<https://zhuanlan.zhihu.com/p/31023929>)

NLP传统模型

[用TF特征向量和simhash指纹计算中文文本的相似度](<https://github.com/zyymax/text-similarity>)

[NLP点滴——文本相似度](https://www.cnblogs.com/xlturing/p/6136690.html)

[海量数据去重之SimHash算法简介和应用](https://blog.csdn.net/u010454030/article/details/49102565)

Python进阶

[关于python的面试题](https://github.com/kenwoodjw/python_interview_question)

[python自测100题](https://zhuanlan.zhihu.com/p/57991045)

数学基础

[distribution-is-all-you-need](https://github.com/graykode/distribution-is-all-you-need)



比赛经验

[AI Challenger 2018 文本挖掘类竞赛相关解决方案及代码汇总](http://www.52nlp.cn/ai-challenger-2018-%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98%E7%B1%BB%E7%AB%9E%E8%B5%9B%E7%9B%B8%E5%85%B3%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E5%8F%8A%E4%BB%A3%E7%A0%81%E6%B1%87%E6%80%BB)

[Kaggle混分记](https://zhuanlan.zhihu.com/p/56747391)

[Kaggle QIQC比赛总结](https://zhuanlan.zhihu.com/p/57015732#comments)

[AI Challenger 2018 细粒度用户评论情感分析，排名17th](https://github.com/BigHeartC/Al_challenger_2018_sentiment_analysis)



面经

[2018-暑期实习生-自然语言处理算法岗-面试题](https://blog.csdn.net/qq_28031525/article/details/80028055)

[2019秋招｜11家互联网公司，NLP面经回馈](https://zhuanlan.zhihu.com/p/46999592)

[国内大互联网公司深度学习面试题](https://zhuanlan.zhihu.com/p/28290988)

[woaidapaopao的博客](https://blog.csdn.net/woaidapaopao)

[路曼曼其修远兮的知乎专栏](<https://zhuanlan.zhihu.com/jiqixuexi>)

[DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)

[Algorithm_Interview_Notes-Chinese](https://github.com/imhuay/Algorithm_Interview_Notes-Chinese)
